{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "mount_file_id": "1mNqJ2oIyWv8AzeFB9-cRhNhTW_aA9-4f",
      "authorship_tag": "ABX9TyMFzOTZrUg6Y57ceKkdR2Yn",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/michellecxy015/search-engines/blob/main/code/google_clip.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7wRaTQ9ESGsg",
        "outputId": "f13de350-bbd1-4353-af6d-aba54f43e29d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (2.2.2)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (2.5.1+cu121)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.10/dist-packages (0.20.1+cu121)\n",
            "Requirement already satisfied: transformers in /usr/local/lib/python3.10/dist-packages (4.46.3)\n",
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.10/dist-packages (11.0.0)\n",
            "Requirement already satisfied: numpy>=1.22.4 in /usr/local/lib/python3.10/dist-packages (from pandas) (1.26.4)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas) (2024.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.10/dist-packages (from pandas) (2024.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch) (3.16.1)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch) (4.12.2)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch) (3.1.4)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch) (2024.10.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.10/dist-packages (from torch) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy==1.13.1->torch) (1.3.0)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.23.2 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.26.3)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (24.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (6.0.2)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (2024.9.11)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers) (2.32.3)\n",
            "Requirement already satisfied: tokenizers<0.21,>=0.20 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.20.3)\n",
            "Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.4.5)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers) (4.66.6)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas) (1.16.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch) (3.0.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.4.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2024.8.30)\n"
          ]
        }
      ],
      "source": [
        "pip install pandas torch torchvision transformers Pillow"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import base64\n",
        "from io import BytesIO\n",
        "from PIL import Image\n",
        "import requests\n",
        "from transformers import CLIPProcessor, CLIPModel\n",
        "\n",
        "# Load CLIP model and processor\n",
        "model = CLIPModel.from_pretrained(\"openai/clip-vit-base-patch32\")\n",
        "processor = CLIPProcessor.from_pretrained(\"openai/clip-vit-base-patch32\")\n",
        "\n",
        "# Define categories with prompts\n",
        "categories = {\n",
        "    \"safe for children\": [\n",
        "        \"This image is suitable for children.\",\n",
        "        \"This image contains friendly and educational content.\",\n",
        "        \"This image is child-appropriate.\",\n",
        "        \"This image contains no harmful or inappropriate content.\"\n",
        "    ],\n",
        "    \"violence\": [\n",
        "        \"This image depicts violence.\",\n",
        "        \"This image contains weapons.\",\n",
        "        \"This image depicts fights or bullying.\",\n",
        "        \"This image contains blood or gore.\"\n",
        "    ],\n",
        "    \"sexual content\": [\n",
        "        \"This image contains nudity.\",\n",
        "        \"This image is sexually explicit.\",\n",
        "        \"This image is pornographic.\",\n",
        "        \"This image contains inappropriate sexual content.\"\n",
        "    ],\n",
        "    \"scary or shocking\": [\n",
        "        \"This image is scary or disturbing.\",\n",
        "        \"This image depicts horror or fear.\",\n",
        "        \"This image is dark and creepy.\",\n",
        "        \"This image is shocking or disgusting.\"\n",
        "    ]\n",
        "}\n",
        "\n",
        "# Function to process image from \"Image URL\" (Base64 or HTTP URL)\n",
        "def process_image(src):\n",
        "    if src.startswith(\"data:image\"):  # Base64-encoded image\n",
        "        base64_data = src.split(\",\")[1]  # Extract Base64 data\n",
        "        image_data = base64.b64decode(base64_data)\n",
        "        image = Image.open(BytesIO(image_data)).convert(\"RGB\")\n",
        "    elif src.startswith(\"http\"):  # URL of the image\n",
        "        response = requests.get(src, stream=True)\n",
        "        if response.status_code == 200:\n",
        "            image = Image.open(response.raw).convert(\"RGB\")\n",
        "        else:\n",
        "            raise ValueError(f\"Failed to fetch image from URL: {src}\")\n",
        "    else:\n",
        "        raise ValueError(\"Unsupported image format.\")\n",
        "    return image\n"
      ],
      "metadata": {
        "id": "6gvB3N1OSTwE"
      },
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Function to classify an image using CLIP\n",
        "def classify_image(image):\n",
        "    # Flatten prompts\n",
        "    prompts = []\n",
        "    labels = []\n",
        "    for category, descriptions in categories.items():\n",
        "        prompts.extend(descriptions)\n",
        "        labels.extend([category] * len(descriptions))\n",
        "\n",
        "    # Process inputs for CLIP\n",
        "    inputs = processor(text=prompts, images=image, return_tensors=\"pt\", padding=True)\n",
        "    outputs = model(**inputs)\n",
        "\n",
        "    # Get logits and probabilities\n",
        "    logits_per_image = outputs.logits_per_image  # Logits for image-text pairs\n",
        "    probs = logits_per_image.softmax(dim=1)  # Convert to probabilities\n",
        "\n",
        "    # Calculate summed probabilities\n",
        "    category_probs_sum = {}\n",
        "    for i, label in enumerate(labels):\n",
        "        category_probs_sum[label] = category_probs_sum.get(label, 0) + probs[0][i].item()\n",
        "\n",
        "    # Find the category with the maximum summed probability\n",
        "    most_likely_label = max(category_probs_sum, key=category_probs_sum.get)\n",
        "    confidence = category_probs_sum[most_likely_label]\n",
        "\n",
        "    return most_likely_label, confidence, category_probs_sum"
      ],
      "metadata": {
        "id": "KtEyDsf5ZRph"
      },
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Load the CSV file\n",
        "csv_path = \"/content/drive/MyDrive/filter_image_metadata.csv\"  # Replace with your actual CSV file path\n",
        "data = pd.read_csv(csv_path)\n",
        "\n",
        "# Initialize results lists\n",
        "labels = []\n",
        "confidences = []\n",
        "categories_probs = []\n",
        "safe_60_flags = []\n",
        "safe_70_flags = []\n",
        "safe_80_flags = []\n",
        "safe_50_flags = []\n",
        "\n",
        "# Classify each image\n",
        "for i, row in data.iterrows():\n",
        "    try:\n",
        "        # Process the image and classify\n",
        "        image = process_image(row[\"Image URL\"])  # Replace \"Image URL\" with your column name\n",
        "        label, confidence, category_probs = classify_image(image)\n",
        "\n",
        "        # Append classification results\n",
        "        labels.append(label)\n",
        "        confidences.append(confidence)\n",
        "        categories_probs.append(category_probs)\n",
        "\n",
        "        # Apply thresholds\n",
        "        safe_60_flags.append(label == \"safe for children\" and confidence >= 0.6)\n",
        "        safe_70_flags.append(label == \"safe for children\" and confidence >= 0.7)\n",
        "        safe_80_flags.append(label == \"safe for children\" and confidence >= 0.8)\n",
        "        safe_50_flags.append(label == \"safe for children\" and confidence >= 0.5)\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"Error processing row {i}: {e}\")\n",
        "        labels.append(\"Error\")\n",
        "        confidences.append(0)\n",
        "        categories_probs.append({})\n",
        "        safe_60_flags.append(False)\n",
        "        safe_70_flags.append(False)\n",
        "        safe_80_flags.append(False)\n",
        "        safe_50_flags.append(False)\n",
        "\n",
        "# Add results to the DataFrame\n",
        "data[\"most_likely_label\"] = labels\n",
        "data[\"confidence\"] = confidences\n",
        "data[\"category_probs\"] = categories_probs\n",
        "data[\"safe_60\"] = safe_60_flags\n",
        "data[\"safe_70\"] = safe_70_flags\n",
        "data[\"safe_80\"] = safe_80_flags\n",
        "data[\"safe_50_flags\"] = safe_50_flags\n",
        "\n",
        "# Save the updated DataFrame to a new CSV file\n",
        "output_csv_path = \"/content/drive/MyDrive/filter_classified_images_with_thresholds.csv\"\n",
        "data.to_csv(output_csv_path, index=False)\n",
        "print(f\"Classification completed and saved to {output_csv_path}.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cF6IJGMIej1j",
        "outputId": "ca67aec5-5001-4151-f728-5fca35f719f0"
      },
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Classification completed and saved to /content/drive/MyDrive/filter_classified_images_with_thresholds.csv.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "L9IVE3OxwrsV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Load the CSV file\n",
        "csv_path = \"/content/drive/MyDrive/unfilter_image_metadata.csv\"  # Replace with your actual CSV file path\n",
        "data = pd.read_csv(csv_path)\n",
        "\n",
        "# Initialize results lists\n",
        "labels = []\n",
        "confidences = []\n",
        "categories_probs = []\n",
        "safe_60_flags = []\n",
        "safe_70_flags = []\n",
        "safe_80_flags = []\n",
        "safe_50_flags = []\n",
        "\n",
        "# Classify each image\n",
        "for i, row in data.iterrows():\n",
        "    try:\n",
        "        # Process the image and classify\n",
        "        image = process_image(row[\"Image URL\"])  # Replace \"Image URL\" with your column name\n",
        "        label, confidence, category_probs = classify_image(image)\n",
        "\n",
        "        # Append classification results\n",
        "        labels.append(label)\n",
        "        confidences.append(confidence)\n",
        "        categories_probs.append(category_probs)\n",
        "\n",
        "        # Apply thresholds\n",
        "        safe_60_flags.append(label == \"safe for children\" and confidence >= 0.6)\n",
        "        safe_70_flags.append(label == \"safe for children\" and confidence >= 0.7)\n",
        "        safe_80_flags.append(label == \"safe for children\" and confidence >= 0.8)\n",
        "        safe_50_60_flags.append(label == \"safe for children\" and confidence >= 0.5)\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"Error processing row {i}: {e}\")\n",
        "        labels.append(\"Error\")\n",
        "        confidences.append(0)\n",
        "        categories_probs.append({})\n",
        "        safe_60_flags.append(False)\n",
        "        safe_70_flags.append(False)\n",
        "        safe_80_flags.append(False)\n",
        "        safe_50_flags.append(False)\n",
        "\n",
        "# Add results to the DataFrame\n",
        "data[\"most_likely_label\"] = labels\n",
        "data[\"confidence\"] = confidences\n",
        "data[\"category_probs\"] = categories_probs\n",
        "data[\"safe_60\"] = safe_60_flags\n",
        "data[\"safe_70\"] = safe_70_flags\n",
        "data[\"safe_80\"] = safe_80_flags\n",
        "data[\"safe_50_flags\"] = safe_50_flags\n",
        "\n",
        "# Save the updated DataFrame to a new CSV file\n",
        "output_csv_path = \"/content/drive/MyDrive/unfilter_classified_images_with_thresholds.csv\"\n",
        "data.to_csv(output_csv_path, index=False)\n",
        "print(f\"Classification completed and saved to {output_csv_path}.\")"
      ],
      "metadata": {
        "id": "c1xRaOxEhlRP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "uXReuzi6f4K4"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}