{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7wRaTQ9ESGsg",
        "outputId": "f13de350-bbd1-4353-af6d-aba54f43e29d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (2.2.2)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (2.5.1+cu121)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.10/dist-packages (0.20.1+cu121)\n",
            "Requirement already satisfied: transformers in /usr/local/lib/python3.10/dist-packages (4.46.3)\n",
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.10/dist-packages (11.0.0)\n",
            "Requirement already satisfied: numpy>=1.22.4 in /usr/local/lib/python3.10/dist-packages (from pandas) (1.26.4)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas) (2024.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.10/dist-packages (from pandas) (2024.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch) (3.16.1)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch) (4.12.2)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch) (3.1.4)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch) (2024.10.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.10/dist-packages (from torch) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy==1.13.1->torch) (1.3.0)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.23.2 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.26.3)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (24.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (6.0.2)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (2024.9.11)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers) (2.32.3)\n",
            "Requirement already satisfied: tokenizers<0.21,>=0.20 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.20.3)\n",
            "Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.4.5)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers) (4.66.6)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas) (1.16.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch) (3.0.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.4.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2024.8.30)\n"
          ]
        }
      ],
      "source": [
        "pip install pandas torch torchvision transformers Pillow"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import base64\n",
        "from io import BytesIO\n",
        "from PIL import Image\n",
        "import requests\n",
        "from transformers import CLIPProcessor, CLIPModel\n",
        "\n",
        "# Load CLIP model and processor\n",
        "model = CLIPModel.from_pretrained(\"openai/clip-vit-base-patch32\")\n",
        "processor = CLIPProcessor.from_pretrained(\"openai/clip-vit-base-patch32\")\n",
        "\n",
        "# Define categories with prompts\n",
        "categories = {\n",
        "    \"safe for children\": [\n",
        "        \"This image is suitable for children.\",\n",
        "        \"This image contains friendly and educational content.\",\n",
        "        \"This image is child-appropriate.\",\n",
        "        \"This image contains no harmful or inappropriate content.\"\n",
        "    ],\n",
        "    \"violence\": [\n",
        "        \"This image depicts violence.\",\n",
        "        \"This image contains weapons.\",\n",
        "        \"This image depicts fights or bullying.\",\n",
        "        \"This image contains blood or gore.\"\n",
        "    ],\n",
        "    \"sexual content\": [\n",
        "        \"This image contains nudity.\",\n",
        "        \"This image is sexually explicit.\",\n",
        "        \"This image is pornographic.\",\n",
        "        \"This image contains inappropriate sexual content.\"\n",
        "    ],\n",
        "    \"scary or shocking\": [\n",
        "        \"This image is scary or disturbing.\",\n",
        "        \"This image depicts horror or fear.\",\n",
        "        \"This image is dark and creepy.\",\n",
        "        \"This image is shocking or disgusting.\"\n",
        "    ]\n",
        "}\n",
        "\n",
        "# Function to process image from \"Image URL\" (Base64 or HTTP URL)\n",
        "def process_image(src):\n",
        "    if src.startswith(\"data:image\"):  # Base64-encoded image\n",
        "        base64_data = src.split(\",\")[1]  # Extract Base64 data\n",
        "        image_data = base64.b64decode(base64_data)\n",
        "        image = Image.open(BytesIO(image_data)).convert(\"RGB\")\n",
        "    elif src.startswith(\"http\"):  # URL of the image\n",
        "        response = requests.get(src, stream=True)\n",
        "        if response.status_code == 200:\n",
        "            image = Image.open(response.raw).convert(\"RGB\")\n",
        "        else:\n",
        "            raise ValueError(f\"Failed to fetch image from URL: {src}\")\n",
        "    else:\n",
        "        raise ValueError(\"Unsupported image format.\")\n",
        "    return image\n"
      ],
      "metadata": {
        "id": "6gvB3N1OSTwE"
      },
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Function to classify an image using CLIP\n",
        "def classify_image(image):\n",
        "    # Flatten prompts\n",
        "    prompts = []\n",
        "    labels = []\n",
        "    for category, descriptions in categories.items():\n",
        "        prompts.extend(descriptions)\n",
        "        labels.extend([category] * len(descriptions))\n",
        "\n",
        "    # Process inputs for CLIP\n",
        "    inputs = processor(text=prompts, images=image, return_tensors=\"pt\", padding=True)\n",
        "    outputs = model(**inputs)\n",
        "\n",
        "    # Get logits and probabilities\n",
        "    logits_per_image = outputs.logits_per_image  # Logits for image-text pairs\n",
        "    probs = logits_per_image.softmax(dim=1)  # Convert to probabilities\n",
        "\n",
        "    # Calculate summed probabilities\n",
        "    category_probs_sum = {}\n",
        "    for i, label in enumerate(labels):\n",
        "        category_probs_sum[label] = category_probs_sum.get(label, 0) + probs[0][i].item()\n",
        "\n",
        "    # Find the category with the maximum summed probability\n",
        "    most_likely_label = max(category_probs_sum, key=category_probs_sum.get)\n",
        "    confidence = category_probs_sum[most_likely_label]\n",
        "\n",
        "    return most_likely_label, confidence, category_probs_sum"
      ],
      "metadata": {
        "id": "KtEyDsf5ZRph"
      },
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Load the CSV file\n",
        "csv_path = \"/content/drive/MyDrive/filter_image_metadata.csv\"  # Replace with your actual CSV file path\n",
        "data = pd.read_csv(csv_path)\n",
        "\n",
        "# Initialize results lists\n",
        "labels = []\n",
        "confidences = []\n",
        "categories_probs = []\n",
        "safe_60_flags = []\n",
        "safe_70_flags = []\n",
        "safe_80_flags = []\n",
        "safe_50_60_flags = []\n",
        "\n",
        "# Classify each image\n",
        "for i, row in data.iterrows():\n",
        "    try:\n",
        "        # Process the image and classify\n",
        "        image = process_image(row[\"Image URL\"])  # Replace \"Image URL\" with your column name\n",
        "        label, confidence, category_probs = classify_image(image)\n",
        "\n",
        "        # Append classification results\n",
        "        labels.append(label)\n",
        "        confidences.append(confidence)\n",
        "        categories_probs.append(category_probs)\n",
        "\n",
        "        # Apply thresholds\n",
        "        safe_60_flags.append(label == \"safe for children\" and confidence >= 0.6)\n",
        "        safe_70_flags.append(label == \"safe for children\" and confidence >= 0.7)\n",
        "        safe_80_flags.append(label == \"safe for children\" and confidence >= 0.8)\n",
        "        safe_50_60_flags.append(label == \"safe for children\" and 0.5 <= confidence < 0.6)\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"Error processing row {i}: {e}\")\n",
        "        labels.append(\"Error\")\n",
        "        confidences.append(0)\n",
        "        categories_probs.append({})\n",
        "        safe_60_flags.append(False)\n",
        "        safe_70_flags.append(False)\n",
        "        safe_80_flags.append(False)\n",
        "        safe_50_60_flags.append(False)\n",
        "\n",
        "# Add results to the DataFrame\n",
        "data[\"most_likely_label\"] = labels\n",
        "data[\"confidence\"] = confidences\n",
        "data[\"category_probs\"] = categories_probs\n",
        "data[\"safe_60\"] = safe_60_flags\n",
        "data[\"safe_70\"] = safe_70_flags\n",
        "data[\"safe_80\"] = safe_80_flags\n",
        "data[\"safe_50_60_flags\"] = safe_50_60_flags\n",
        "\n",
        "# Save the updated DataFrame to a new CSV file\n",
        "output_csv_path = \"/content/drive/MyDrive/filter_classified_images_with_thresholds.csv\"\n",
        "data.to_csv(output_csv_path, index=False)\n",
        "print(f\"Classification completed and saved to {output_csv_path}.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cF6IJGMIej1j",
        "outputId": "ca67aec5-5001-4151-f728-5fca35f719f0"
      },
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Classification completed and saved to /content/drive/MyDrive/filter_classified_images_with_thresholds.csv.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(data.head(5))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RxZIvI3Q98px",
        "outputId": "778e34f9-acc7-4ec5-e40f-fa146b46c717"
      },
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Entity Type  Entity Harmful Type Harmful Term     Search Term  \\\n",
            "0        game  Roblox     violence      torture  Roblox torture   \n",
            "1        game  Roblox     violence      torture  Roblox torture   \n",
            "2        game  Roblox     violence      torture  Roblox torture   \n",
            "3        game  Roblox     violence      torture  Roblox torture   \n",
            "4        game  Roblox     violence      torture  Roblox torture   \n",
            "\n",
            "  SafeSearch Mode               File Name  \\\n",
            "0          filter  Roblox torture_image_1   \n",
            "1          filter  Roblox torture_image_2   \n",
            "2          filter  Roblox torture_image_3   \n",
            "3          filter  Roblox torture_image_4   \n",
            "4          filter  Roblox torture_image_5   \n",
            "\n",
            "                                           Image URL     X    Y  Width  \\\n",
            "0  data:image/jpeg;base64,/9j/4AAQSkZJRgABAQAAAQA...    20  161    292   \n",
            "1  data:image/jpeg;base64,/9j/4AAQSkZJRgABAQAAAQA...   332  161    293   \n",
            "2  data:image/jpeg;base64,/9j/4AAQSkZJRgABAQAAAQA...   645  161    293   \n",
            "3  data:image/jpeg;base64,/9j/4AAQSkZJRgABAQAAAQA...   958  161    293   \n",
            "4  data:image/jpeg;base64,/9j/4AAQSkZJRgABAQAAAQA...  1271  155    240   \n",
            "\n",
            "   Height most_likely_label  confidence  \\\n",
            "0     168          violence    0.481385   \n",
            "1     168          violence    0.596223   \n",
            "2     168          violence    0.441169   \n",
            "3     168          violence    0.421254   \n",
            "4     180          violence    0.737617   \n",
            "\n",
            "                                      category_probs  safe_60  safe_70  \\\n",
            "0  {'safe for children': 0.26060543954372406, 'vi...    False    False   \n",
            "1  {'safe for children': 0.1863415353000164, 'vio...    False    False   \n",
            "2  {'safe for children': 0.23962891474366188, 'vi...    False    False   \n",
            "3  {'safe for children': 0.1901299450546503, 'vio...    False    False   \n",
            "4  {'safe for children': 0.029038085136562586, 'v...    False    False   \n",
            "\n",
            "   safe_80  safe_50_60_flags  \n",
            "0    False             False  \n",
            "1    False             False  \n",
            "2    False             False  \n",
            "3    False             False  \n",
            "4    False             False  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Load the CSV file\n",
        "csv_path = \"/content/drive/MyDrive/unfilter_image_metadata.csv\"  # Replace with your actual CSV file path\n",
        "data = pd.read_csv(csv_path)\n",
        "\n",
        "# Initialize results lists\n",
        "labels = []\n",
        "confidences = []\n",
        "categories_probs = []\n",
        "safe_60_flags = []\n",
        "safe_70_flags = []\n",
        "safe_80_flags = []\n",
        "safe_50_60_flags = []\n",
        "\n",
        "# Classify each image\n",
        "for i, row in data.iterrows():\n",
        "    try:\n",
        "        # Process the image and classify\n",
        "        image = process_image(row[\"Image URL\"])  # Replace \"Image URL\" with your column name\n",
        "        label, confidence, category_probs = classify_image(image)\n",
        "\n",
        "        # Append classification results\n",
        "        labels.append(label)\n",
        "        confidences.append(confidence)\n",
        "        categories_probs.append(category_probs)\n",
        "\n",
        "        # Apply thresholds\n",
        "        safe_60_flags.append(label == \"safe for children\" and confidence >= 0.6)\n",
        "        safe_70_flags.append(label == \"safe for children\" and confidence >= 0.7)\n",
        "        safe_80_flags.append(label == \"safe for children\" and confidence >= 0.8)\n",
        "        safe_50_60_flags.append(label == \"safe for children\" and 0.5 <= confidence < 0.6)\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"Error processing row {i}: {e}\")\n",
        "        labels.append(\"Error\")\n",
        "        confidences.append(0)\n",
        "        categories_probs.append({})\n",
        "        safe_60_flags.append(False)\n",
        "        safe_70_flags.append(False)\n",
        "        safe_80_flags.append(False)\n",
        "        safe_50_60_flags.append(False)\n",
        "\n",
        "# Add results to the DataFrame\n",
        "data[\"most_likely_label\"] = labels\n",
        "data[\"confidence\"] = confidences\n",
        "data[\"category_probs\"] = categories_probs\n",
        "data[\"safe_60\"] = safe_60_flags\n",
        "data[\"safe_70\"] = safe_70_flags\n",
        "data[\"safe_80\"] = safe_80_flags\n",
        "data[\"safe_50_60_flags\"] = safe_50_60_flags\n",
        "\n",
        "# Save the updated DataFrame to a new CSV file\n",
        "output_csv_path = \"/content/drive/MyDrive/unfilter_classified_images_with_thresholds.csv\"\n",
        "data.to_csv(output_csv_path, index=False)\n",
        "print(f\"Classification completed and saved to {output_csv_path}.\")"
      ],
      "metadata": {
        "id": "c1xRaOxEhlRP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "Gw9wCU33pePa",
        "outputId": "76076e11-b459-4e33-aead-0a1dfb07e3d1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "uXReuzi6f4K4"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}